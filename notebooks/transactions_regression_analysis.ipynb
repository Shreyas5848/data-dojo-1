{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b58979",
   "metadata": {},
   "source": [
    "# üìà Regression Analysis: transactions\n",
    "\n",
    "**Generated:** 2025-12-09 16:01:22  \n",
    "**Type:** Regression Modeling  \n",
    "**Dataset:** transactions\n",
    "\n",
    "## üéØ Objective\n",
    "This notebook provides a complete regression modeling workflow to predict continuous numerical values.\n",
    "\n",
    "## üìã Workflow Steps\n",
    "1. **Data Loading & Exploration**\n",
    "2. **Target Variable Analysis**\n",
    "3. **Feature Engineering & Preprocessing**\n",
    "4. **Model Training & Comparison**\n",
    "5. **Model Evaluation & Metrics**\n",
    "6. **Residual Analysis**\n",
    "7. **Predictions & Business Insights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef9b9a7",
   "metadata": {},
   "source": [
    "## 1. üìÅ Data Loading & Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0eae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset - REPLACE 'transactions.csv' with your actual file path\n",
    "df = pd.read_csv('transactions.csv')\n",
    "\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(\"\\n=== DATA TYPES ===\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n=== FIRST 5 ROWS ===\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_data = df.isnull().sum()\n",
    "if missing_data.sum() > 0:\n",
    "    print(missing_data[missing_data > 0])\n",
    "else:\n",
    "    print(\"No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de9b0b",
   "metadata": {},
   "source": [
    "## 2. üéØ Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Define your target variable here\n",
    "# REPLACE 'target_column' with your actual target column name\n",
    "target_column = 'target_column'  # ‚ö†Ô∏è UPDATE THIS WITH YOUR TARGET COLUMN\n",
    "\n",
    "# Check if target column exists\n",
    "if target_column in df.columns:\n",
    "    print(f\"‚úÖ Target variable found: {target_column}\")\n",
    "    \n",
    "    # Target statistics\n",
    "    print(\"\\n=== TARGET VARIABLE STATISTICS ===\")\n",
    "    print(f\"Mean: {df[target_column].mean():.4f}\")\n",
    "    print(f\"Median: {df[target_column].median():.4f}\")\n",
    "    print(f\"Std Dev: {df[target_column].std():.4f}\")\n",
    "    print(f\"Min: {df[target_column].min():.4f}\")\n",
    "    print(f\"Max: {df[target_column].max():.4f}\")\n",
    "    print(f\"Skewness: {df[target_column].skew():.4f}\")\n",
    "    print(f\"Kurtosis: {df[target_column].kurtosis():.4f}\")\n",
    "    \n",
    "    # Visualize target distribution\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(df[target_column], bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.axvline(df[target_column].mean(), color='red', linestyle='--', label=f'Mean: {df[target_column].mean():.2f}')\n",
    "    plt.axvline(df[target_column].median(), color='green', linestyle='--', label=f'Median: {df[target_column].median():.2f}')\n",
    "    plt.xlabel(target_column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {target_column}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.boxplot(df[target_column].dropna())\n",
    "    plt.ylabel(target_column)\n",
    "    plt.title(f'Box Plot of {target_column}')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    from scipy import stats\n",
    "    stats.probplot(df[target_column].dropna(), dist=\"norm\", plot=plt)\n",
    "    plt.title('Q-Q Plot (Normality Check)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Check for outliers\n",
    "    Q1 = df[target_column].quantile(0.25)\n",
    "    Q3 = df[target_column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((df[target_column] < Q1 - 1.5*IQR) | (df[target_column] > Q3 + 1.5*IQR)).sum()\n",
    "    print(f\"\\nüìä Outliers detected (IQR method): {outliers} ({outliers/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Skewness check\n",
    "    skewness = df[target_column].skew()\n",
    "    if abs(skewness) > 1:\n",
    "        print(f\"‚ö†Ô∏è  Target is highly skewed ({skewness:.2f}). Consider log transformation.\")\n",
    "    elif abs(skewness) > 0.5:\n",
    "        print(f\"üìä Target is moderately skewed ({skewness:.2f}).\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Target distribution is approximately normal ({skewness:.2f}).\")\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Column '{target_column}' not found!\")\n",
    "    print(f\"Available columns: {list(df.columns)}\")\n",
    "    print(\"\\nPlease update the 'target_column' variable above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c00d7",
   "metadata": {},
   "source": [
    "## 3. üìä Feature Analysis & Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze features and their correlation with target\n",
    "if target_column in df.columns:\n",
    "    \n",
    "    # Identify feature columns (exclude target and ID columns)\n",
    "    id_columns = ['id', 'ID', 'index', 'customer_id', 'user_id']\n",
    "    feature_columns = [col for col in df.columns \n",
    "                      if col != target_column and col not in id_columns]\n",
    "    \n",
    "    X = df[feature_columns].copy()\n",
    "    y = df[target_column].copy()\n",
    "    \n",
    "    print(f\"‚úÖ Features selected: {len(feature_columns)}\")\n",
    "    \n",
    "    # Analyze feature types\n",
    "    numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    print(f\"\\nüìä Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "    print(f\"üìã Categorical features ({len(categorical_features)}): {categorical_features}\")\n",
    "    \n",
    "    # Correlation with target\n",
    "    if len(numeric_features) > 0:\n",
    "        print(\"\\n=== CORRELATION WITH TARGET ===\")\n",
    "        correlations = df[numeric_features + [target_column]].corr()[target_column].drop(target_column)\n",
    "        correlations_sorted = correlations.abs().sort_values(ascending=False)\n",
    "        \n",
    "        print(\"\\nTop correlated features:\")\n",
    "        for feature in correlations_sorted.head(10).index:\n",
    "            corr_value = correlations[feature]\n",
    "            print(f\"  {feature}: {corr_value:.4f}\")\n",
    "        \n",
    "        # Correlation heatmap\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        corr_matrix = df[numeric_features + [target_column]].corr()\n",
    "        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "        plt.title('Feature Correlation Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Scatter plots with target\n",
    "        top_features = correlations_sorted.head(4).index.tolist()\n",
    "        if len(top_features) > 0:\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "            axes = axes.ravel()\n",
    "            \n",
    "            for i, feature in enumerate(top_features[:4]):\n",
    "                axes[i].scatter(df[feature], df[target_column], alpha=0.5)\n",
    "                axes[i].set_xlabel(feature)\n",
    "                axes[i].set_ylabel(target_column)\n",
    "                axes[i].set_title(f'{feature} vs {target_column} (r={correlations[feature]:.3f})')\n",
    "                \n",
    "                # Add trend line\n",
    "                z = np.polyfit(df[feature].dropna(), df[target_column].dropna(), 1)\n",
    "                p = np.poly1d(z)\n",
    "                axes[i].plot(df[feature].sort_values(), p(df[feature].sort_values()), \n",
    "                           \"r--\", alpha=0.8, label='Trend')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "else:\n",
    "    print(\"‚ùå Please define target column first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c180299",
   "metadata": {},
   "source": [
    "## 4. üîß Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ffb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing pipeline\n",
    "if target_column in df.columns and 'X' in locals():\n",
    "    \n",
    "    # Handle missing values\n",
    "    print(\"=== HANDLING MISSING VALUES ===\")\n",
    "    \n",
    "    # For numeric features: fill with median\n",
    "    if len(numeric_features) > 0:\n",
    "        numeric_imputer = SimpleImputer(strategy='median')\n",
    "        X[numeric_features] = numeric_imputer.fit_transform(X[numeric_features])\n",
    "        print(f\"‚úÖ Filled missing values in numeric features with median\")\n",
    "    \n",
    "    # For categorical features: fill with mode and encode\n",
    "    if len(categorical_features) > 0:\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        X[categorical_features] = categorical_imputer.fit_transform(X[categorical_features])\n",
    "        \n",
    "        # Encode categorical variables\n",
    "        label_encoders = {}\n",
    "        for col in categorical_features:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "            print(f\"‚úÖ Encoded {col}: {len(le.classes_)} unique values\")\n",
    "    \n",
    "    # Handle missing values in target\n",
    "    if y.isnull().sum() > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Dropping {y.isnull().sum()} rows with missing target values\")\n",
    "        valid_idx = y.notna()\n",
    "        X = X[valid_idx]\n",
    "        y = y[valid_idx]\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Preprocessing completed!\")\n",
    "    print(f\"Final feature matrix shape: {X.shape}\")\n",
    "    print(f\"Target variable shape: {y.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please complete previous steps first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a31b5",
   "metadata": {},
   "source": [
    "## 5. üöÇ Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8cbdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "if 'X' in locals() and 'y' in locals():\n",
    "    \n",
    "    test_size = 0.2  # 80% train, 20% test\n",
    "    random_state = 42\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Also create scaled versions\n",
    "    X_train_scaled, X_test_scaled, _, _ = train_test_split(\n",
    "        X_scaled_df, y,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(\"=== TRAIN-TEST SPLIT COMPLETED ===\")\n",
    "    print(f\"Training set: {X_train.shape}\")\n",
    "    print(f\"Test set: {X_test.shape}\")\n",
    "    \n",
    "    print(\"\\n=== TARGET DISTRIBUTION ===\")\n",
    "    print(f\"Training - Mean: {y_train.mean():.4f}, Std: {y_train.std():.4f}\")\n",
    "    print(f\"Test - Mean: {y_test.mean():.4f}, Std: {y_test.std():.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please complete preprocessing first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323df726",
   "metadata": {},
   "source": [
    "## 6. ü§ñ Model Training & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f71d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple regression models\n",
    "if 'X_train' in locals():\n",
    "    \n",
    "    # Define models to compare\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Ridge Regression': Ridge(alpha=1.0),\n",
    "        'Lasso Regression': Lasso(alpha=0.1),\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "        'K-Nearest Neighbors': KNeighborsRegressor(n_neighbors=5),\n",
    "        'Support Vector Regression': SVR(kernel='rbf')\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    model_results = {}\n",
    "    \n",
    "    print(\"=== TRAINING MULTIPLE MODELS ===\")\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Use scaled data for algorithms that need it\n",
    "        if name in ['Support Vector Regression', 'K-Nearest Neighbors']:\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            y_train_pred = model.predict(X_train_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_train_pred = model.predict(X_train)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        \n",
    "        # MAPE (handle division by zero)\n",
    "        try:\n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred) * 100\n",
    "        except:\n",
    "            mape = np.nan\n",
    "        \n",
    "        model_results[name] = {\n",
    "            'model': model,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2,\n",
    "            'r2_train': r2_train,\n",
    "            'mape': mape,\n",
    "            'predictions': y_pred\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ {name} - R¬≤: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "    \n",
    "    # Display results summary\n",
    "    print(\"\\n=== MODEL COMPARISON SUMMARY ===\")\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': list(model_results.keys()),\n",
    "        'R¬≤ (Test)': [results['r2'] for results in model_results.values()],\n",
    "        'R¬≤ (Train)': [results['r2_train'] for results in model_results.values()],\n",
    "        'RMSE': [results['rmse'] for results in model_results.values()],\n",
    "        'MAE': [results['mae'] for results in model_results.values()],\n",
    "        'MAPE (%)': [results['mape'] for results in model_results.values()]\n",
    "    })\n",
    "    \n",
    "    results_df = results_df.sort_values('R¬≤ (Test)', ascending=False)\n",
    "    display(results_df)\n",
    "    \n",
    "    # Visualize model comparison\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(results_df['Model'], results_df['R¬≤ (Test)'])\n",
    "    plt.xlabel('R¬≤ Score')\n",
    "    plt.title('Model Comparison - R¬≤ Score')\n",
    "    plt.xlim(0, 1)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(results_df['Model'], results_df['RMSE'])\n",
    "    plt.xlabel('RMSE')\n",
    "    plt.title('Model Comparison - RMSE (lower is better)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Select best model\n",
    "    best_model_name = results_df.iloc[0]['Model']\n",
    "    best_model = model_results[best_model_name]['model']\n",
    "    best_predictions = model_results[best_model_name]['predictions']\n",
    "    \n",
    "    print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "    print(f\"   R¬≤ Score: {model_results[best_model_name]['r2']:.4f}\")\n",
    "    print(f\"   RMSE: {model_results[best_model_name]['rmse']:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please complete train-test split first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec34baf",
   "metadata": {},
   "source": [
    "## 7. üìà Detailed Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed evaluation of the best model\n",
    "if 'best_model' in locals():\n",
    "    \n",
    "    print(f\"=== DETAILED EVALUATION: {best_model_name} ===\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = best_predictions\n",
    "    \n",
    "    # Metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\nüìä REGRESSION METRICS:\")\n",
    "    print(f\"R¬≤ Score:        {r2:.4f} ({r2*100:.2f}% variance explained)\")\n",
    "    print(f\"RMSE:            {rmse:.4f}\")\n",
    "    print(f\"MAE:             {mae:.4f}\")\n",
    "    print(f\"MSE:             {mse:.4f}\")\n",
    "    \n",
    "    # Residual analysis\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Actual vs Predicted\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'Actual vs Predicted\\nR¬≤ = {r2:.4f}')\n",
    "    \n",
    "    # Residuals vs Predicted\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title('Residuals vs Predicted Values')\n",
    "    \n",
    "    # Residual distribution\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.axvline(x=0, color='r', linestyle='--')\n",
    "    plt.xlabel('Residual Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Residual Distribution\\nMean: {residuals.mean():.4f}, Std: {residuals.std():.4f}')\n",
    "    \n",
    "    # Q-Q plot for residuals\n",
    "    plt.subplot(2, 2, 4)\n",
    "    from scipy import stats\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title('Q-Q Plot of Residuals')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Residual statistics\n",
    "    print(\"\\nüìä RESIDUAL ANALYSIS:\")\n",
    "    print(f\"Mean Residual:   {residuals.mean():.4f} (should be ~0)\")\n",
    "    print(f\"Std Residual:    {residuals.std():.4f}\")\n",
    "    print(f\"Min Residual:    {residuals.min():.4f}\")\n",
    "    print(f\"Max Residual:    {residuals.max():.4f}\")\n",
    "    \n",
    "    # Check for heteroscedasticity\n",
    "    correlation = np.corrcoef(y_pred, np.abs(residuals))[0, 1]\n",
    "    if abs(correlation) > 0.3:\n",
    "        print(f\"\\n‚ö†Ô∏è  Potential heteroscedasticity detected (correlation: {correlation:.3f})\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ No significant heteroscedasticity (correlation: {correlation:.3f})\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Please complete model training first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b190b9",
   "metadata": {},
   "source": [
    "## 8. üîç Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9461009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance\n",
    "if 'best_model' in locals():\n",
    "    \n",
    "    print(f\"=== FEATURE IMPORTANCE ANALYSIS ===\")\n",
    "    \n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        # Tree-based models\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Importance': best_model.feature_importances_,\n",
    "            'Importance_Percentage': best_model.feature_importances_ * 100\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nüìä TOP 15 MOST IMPORTANT FEATURES:\")\n",
    "        display(importance_df.head(15))\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = importance_df.head(15)\n",
    "        plt.barh(range(len(top_features)), top_features['Importance'])\n",
    "        plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "        plt.xlabel('Feature Importance')\n",
    "        plt.title(f'Top 15 Feature Importance - {best_model_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif hasattr(best_model, 'coef_'):\n",
    "        # Linear models\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature': X.columns,\n",
    "            'Coefficient': best_model.coef_,\n",
    "            'Abs_Coefficient': np.abs(best_model.coef_)\n",
    "        }).sort_values('Abs_Coefficient', ascending=False)\n",
    "        \n",
    "        print(\"\\nüìä TOP 15 FEATURES BY COEFFICIENT MAGNITUDE:\")\n",
    "        display(coef_df.head(15))\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        top_features = coef_df.head(15)\n",
    "        colors = ['green' if c > 0 else 'red' for c in top_features['Coefficient']]\n",
    "        plt.barh(range(len(top_features)), top_features['Coefficient'], color=colors)\n",
    "        plt.yticks(range(len(top_features)), top_features['Feature'])\n",
    "        plt.xlabel('Coefficient Value')\n",
    "        plt.title(f'Top 15 Feature Coefficients - {best_model_name}')\n",
    "        plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\nüí° Interpretation:\")\n",
    "        print(\"‚Ä¢ GREEN bars: Positive effect on target\")\n",
    "        print(\"‚Ä¢ RED bars: Negative effect on target\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Feature importance not available for {best_model_name}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Please complete model training first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7532f0",
   "metadata": {},
   "source": [
    "## 9. üéØ Predictions & Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ffb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze predictions and errors\n",
    "if 'best_model' in locals():\n",
    "    \n",
    "    print(f\"=== PREDICTION ANALYSIS ===\")\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': y_test.values,\n",
    "        'Predicted': best_predictions,\n",
    "        'Residual': y_test.values - best_predictions,\n",
    "        'Abs_Error': np.abs(y_test.values - best_predictions),\n",
    "        'Pct_Error': np.abs(y_test.values - best_predictions) / np.abs(y_test.values) * 100\n",
    "    })\n",
    "    \n",
    "    # Error statistics\n",
    "    print(\"\\nüìä ERROR DISTRIBUTION:\")\n",
    "    print(f\"Mean Absolute Error: {results_df['Abs_Error'].mean():.4f}\")\n",
    "    print(f\"Median Absolute Error: {results_df['Abs_Error'].median():.4f}\")\n",
    "    print(f\"90th Percentile Error: {results_df['Abs_Error'].quantile(0.9):.4f}\")\n",
    "    print(f\"95th Percentile Error: {results_df['Abs_Error'].quantile(0.95):.4f}\")\n",
    "    \n",
    "    # Sample predictions\n",
    "    print(\"\\nüîç SAMPLE PREDICTIONS:\")\n",
    "    sample = results_df.head(15).round(4)\n",
    "    display(sample)\n",
    "    \n",
    "    # Best and worst predictions\n",
    "    print(\"\\n‚úÖ BEST PREDICTIONS (lowest error):\")\n",
    "    display(results_df.nsmallest(5, 'Abs_Error').round(4))\n",
    "    \n",
    "    print(\"\\n‚ùå WORST PREDICTIONS (highest error):\")\n",
    "    display(results_df.nlargest(5, 'Abs_Error').round(4))\n",
    "    \n",
    "    # Error distribution visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(results_df['Abs_Error'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.axvline(results_df['Abs_Error'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {results_df[\"Abs_Error\"].mean():.2f}')\n",
    "    plt.xlabel('Absolute Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Absolute Errors')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(results_df['Pct_Error'].clip(upper=100), bins=50, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel('Percentage Error (%)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Percentage Errors')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please complete model training first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ec3f7",
   "metadata": {},
   "source": [
    "## 10. ‚úÖ Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90945cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and recommendations\n",
    "print(\"=== üìà REGRESSION ANALYSIS COMPLETE ===\")\n",
    "print()\n",
    "\n",
    "if 'best_model' in locals():\n",
    "    r2 = model_results[best_model_name]['r2']\n",
    "    rmse = model_results[best_model_name]['rmse']\n",
    "    mae = model_results[best_model_name]['mae']\n",
    "    \n",
    "    print(\"üìä ANALYSIS SUMMARY:\")\n",
    "    print(f\"‚Ä¢ Dataset: {dataset_name}\")\n",
    "    print(f\"‚Ä¢ Target Variable: {target_column}\")\n",
    "    print(f\"‚Ä¢ Best Model: {best_model_name}\")\n",
    "    print(f\"‚Ä¢ R¬≤ Score: {r2:.4f} ({r2*100:.2f}% variance explained)\")\n",
    "    print(f\"‚Ä¢ RMSE: {rmse:.4f}\")\n",
    "    print(f\"‚Ä¢ MAE: {mae:.4f}\")\n",
    "    print(f\"‚Ä¢ Features Used: {len(X.columns)}\")\n",
    "    print(f\"‚Ä¢ Training Samples: {len(X_train)}\")\n",
    "    print(f\"‚Ä¢ Test Samples: {len(X_test)}\")\n",
    "    \n",
    "    print(\"\\nüöÄ RECOMMENDED NEXT STEPS:\")\n",
    "    \n",
    "    if r2 >= 0.9:\n",
    "        print(\"1. ‚úÖ Excellent model! Ready for production deployment\")\n",
    "        print(\"2. üîÑ Set up model monitoring and retraining pipeline\")\n",
    "        print(\"3. üìà Consider A/B testing in production\")\n",
    "    elif r2 >= 0.7:\n",
    "        print(\"1. üéØ Good performance! Try hyperparameter tuning\")\n",
    "        print(\"2. üîß Consider polynomial features for non-linear relationships\")\n",
    "        print(\"3. üìä Try ensemble methods (stacking, blending)\")\n",
    "    elif r2 >= 0.5:\n",
    "        print(\"1. üîß Feature engineering needed\")\n",
    "        print(\"2. üìä Look for non-linear relationships\")\n",
    "        print(\"3. üéØ Consider more advanced algorithms (XGBoost, LightGBM)\")\n",
    "        print(\"4. üìà Collect more relevant features\")\n",
    "    else:\n",
    "        print(\"1. üîç Review data quality and target definition\")\n",
    "        print(\"2. üéØ Significant feature engineering required\")\n",
    "        print(\"3. üìä Consider if regression is the right approach\")\n",
    "        print(\"4. ü§ù Consult domain experts for insights\")\n",
    "    \n",
    "    print(\"\\nüõ†Ô∏è  TECHNICAL IMPROVEMENTS:\")\n",
    "    print(\"‚Ä¢ Hyperparameter tuning with GridSearchCV/RandomizedSearchCV\")\n",
    "    print(\"‚Ä¢ Cross-validation for more robust evaluation\")\n",
    "    print(\"‚Ä¢ Try XGBoost, LightGBM, or CatBoost\")\n",
    "    print(\"‚Ä¢ Feature selection (RFE, SelectKBest)\")\n",
    "    print(\"‚Ä¢ Polynomial features for non-linear relationships\")\n",
    "    print(\"‚Ä¢ Log transformation if target is skewed\")\n",
    "    \n",
    "    print(\"\\nüíæ SAVE YOUR MODEL:\")\n",
    "    print(\"# Uncomment to save the trained model\")\n",
    "    print(\"# import joblib\")\n",
    "    print(\"# joblib.dump(best_model, 'regression_model.pkl')\")\n",
    "    print(\"# joblib.dump(scaler, 'scaler.pkl')\")\n",
    "    print(\"# print('Model saved successfully!')\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Analysis incomplete. Please run all previous cells.\")\n",
    "\n",
    "print(\"\\nüéâ Regression analysis workflow completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}