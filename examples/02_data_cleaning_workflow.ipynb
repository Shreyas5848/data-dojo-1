{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Workflow with DataDojo\n",
    "\n",
    "This notebook demonstrates how to create and execute a complete data cleaning pipeline using DataDojo's guided approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datadojo import create_dojo\n",
    "from datadojo.contracts.dojo_interface import Domain, Difficulty, GuidanceLevel\n",
    "\n",
    "# Initialize DataDojo\n",
    "dojo = create_dojo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Sample Data\n",
    "\n",
    "Let's create a messy dataset that needs cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset with common data quality issues\n",
    "np.random.seed(42)\n",
    "\n",
    "data = {\n",
    "    'customer_id': list(range(1, 101)) + [50],  # Duplicate\n",
    "    'age': [np.random.randint(18, 80) if i % 10 != 0 else None for i in range(101)],  # Missing values\n",
    "    'income': [np.random.randint(20000, 150000) for _ in range(101)],\n",
    "    'purchase_amount': [np.random.uniform(10, 1000) if i % 15 != 0 else None for i in range(101)],  # Missing\n",
    "    'category': np.random.choice(['Electronics', 'Clothing', 'Food', 'electronics'], 101),  # Inconsistent\n",
    "    'email': [f'user{i}@email.com' if i % 20 != 0 else 'invalid' for i in range(101)]  # Invalid values\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Start a Data Cleaning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an e-commerce project\n",
    "projects = dojo.list_projects(domain=Domain.ECOMMERCE, difficulty=Difficulty.BEGINNER)\n",
    "\n",
    "if projects:\n",
    "    project = dojo.start_project(projects[0].id)\n",
    "    print(f\"ðŸ“Š Project: {project.name}\")\n",
    "    print(f\"Description: {project.description}\")\n",
    "else:\n",
    "    print(\"Creating a custom project...\")\n",
    "    # In production, you'd use dojo.create_project() here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a Data Cleaning Pipeline\n",
    "\n",
    "We'll build a pipeline with multiple processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datadojo.contracts.dojo_interface import OperationType\n",
    "\n",
    "# Create a pipeline with detailed guidance\n",
    "if projects:\n",
    "    pipeline = project.create_pipeline(\n",
    "        \"customer_data_cleaning\",\n",
    "        guidance_level=GuidanceLevel.DETAILED\n",
    "    )\n",
    "    \n",
    "    # Add steps to the pipeline\n",
    "    pipeline.add_step(\n",
    "        step_id=\"remove_duplicates\",\n",
    "        name=\"Remove Duplicate Records\",\n",
    "        operation_type=OperationType.DATA_CLEANING,\n",
    "        description=\"Identify and remove duplicate customer records\",\n",
    "        learned_concepts=[\"duplicates\"]\n",
    "    )\n",
    "    \n",
    "    pipeline.add_step(\n",
    "        step_id=\"handle_missing_age\",\n",
    "        name=\"Handle Missing Age Values\",\n",
    "        operation_type=OperationType.DATA_CLEANING,\n",
    "        description=\"Fill or remove missing age values\",\n",
    "        learned_concepts=[\"missing_values\"],\n",
    "        prerequisites=[\"remove_duplicates\"]\n",
    "    )\n",
    "    \n",
    "    pipeline.add_step(\n",
    "        step_id=\"standardize_categories\",\n",
    "        name=\"Standardize Category Names\",\n",
    "        operation_type=OperationType.TRANSFORMATION,\n",
    "        description=\"Make category names consistent\",\n",
    "        learned_concepts=[\"data_quality\"],\n",
    "        prerequisites=[\"handle_missing_age\"]\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Pipeline created with 3 steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Learn About the Concepts\n",
    "\n",
    "Before processing, let's understand the concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "educational = dojo.get_educational_interface()\n",
    "\n",
    "# Learn about duplicates\n",
    "duplicates_concept = educational.get_concept_explanation(\"duplicates\")\n",
    "if duplicates_concept:\n",
    "    print(f\"ðŸ“š {duplicates_concept.title}\\n\")\n",
    "    print(duplicates_concept.get_summary(max_length=200))\n",
    "    \n",
    "    if duplicates_concept.examples:\n",
    "        print(f\"\\nðŸ’» Example:\\n{duplicates_concept.examples[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Implement the Cleaning Steps\n",
    "\n",
    "Now let's actually clean the data, step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicates\n",
    "print(\"Step 1: Remove Duplicates\")\n",
    "print(f\"Before: {len(df)} rows\")\n",
    "df_clean = df.drop_duplicates(subset=['customer_id'], keep='first')\n",
    "print(f\"After: {len(df_clean)} rows\")\n",
    "print(f\"Removed {len(df) - len(df_clean)} duplicate(s)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Handle missing age values\n",
    "print(\"Step 2: Handle Missing Age Values\")\n",
    "print(f\"Missing age values: {df_clean['age'].isnull().sum()}\")\n",
    "\n",
    "# Fill with median\n",
    "median_age = df_clean['age'].median()\n",
    "df_clean['age'] = df_clean['age'].fillna(median_age)\n",
    "print(f\"Filled with median age: {median_age}\")\n",
    "print(f\"Missing values after: {df_clean['age'].isnull().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Standardize categories\n",
    "print(\"Step 3: Standardize Category Names\")\n",
    "print(f\"Categories before: {df_clean['category'].unique()}\")\n",
    "\n",
    "# Convert to lowercase and capitalize first letter\n",
    "df_clean['category'] = df_clean['category'].str.lower().str.capitalize()\n",
    "print(f\"Categories after: {df_clean['category'].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Validate the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Quality Report:\")\n",
    "print(f\"  Total rows: {len(df_clean)}\")\n",
    "print(f\"  Total columns: {len(df_clean.columns)}\")\n",
    "print(f\"  Missing values: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"  Duplicate rows: {df_clean.duplicated().sum()}\")\n",
    "print(f\"\\nCleaned data preview:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Track Your Progress\n",
    "\n",
    "DataDojo tracks your completed steps and learned concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track progress\n",
    "progress = educational.get_progress(\"student-1\", project.id if projects else \"custom-project\")\n",
    "\n",
    "# Mark steps as completed\n",
    "progress.complete_step(\"remove_duplicates\")\n",
    "progress.complete_step(\"handle_missing_age\")\n",
    "progress.complete_step(\"standardize_categories\")\n",
    "\n",
    "# Mark concepts as learned\n",
    "progress.learn_concept(\"duplicates\")\n",
    "progress.learn_concept(\"missing_values\")\n",
    "progress.learn_concept(\"data_quality\")\n",
    "\n",
    "# Update skill scores\n",
    "progress.update_skill_score(\"data_cleaning\", 85.0)\n",
    "\n",
    "print(f\"Progress Summary:\")\n",
    "print(f\"  Completed steps: {len(progress.completed_steps)}\")\n",
    "print(f\"  Learned concepts: {len(progress.learned_concepts)}\")\n",
    "print(f\"  Average skill score: {progress.get_average_skill_score():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned how to:\n",
    "\n",
    "âœ… Create a data cleaning pipeline\n",
    "âœ… Handle common data quality issues\n",
    "âœ… Use educational concepts to understand the process\n",
    "âœ… Track your learning progress\n",
    "\n",
    "Next steps:\n",
    "- Try the **03_progress_tracking.ipynb** notebook to visualize your learning journey\n",
    "- Explore **04_custom_pipelines.ipynb** to build more advanced pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
