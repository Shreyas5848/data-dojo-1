{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd942997",
   "metadata": {},
   "source": [
    "# ðŸ“Š Exploratory Data Analysis: bank_transactions\n",
    "\n",
    "**Generated:** 2025-12-09 12:52:15  \n",
    "**Dataset:** bank_transactions  \n",
    "**Profile Results:** 1000 rows, 15 columns\n",
    "\n",
    "This notebook provides comprehensive analysis of your dataset based on DataDojo profiling results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e19d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab038ebc",
   "metadata": {},
   "source": [
    "## 1. ðŸ“ Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ef3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('D:\\data-dojo-1\\datasets\\finance\\bank_transactions.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935c32d",
   "metadata": {},
   "source": [
    "## 2. ðŸ” Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b077c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_summary = df.isnull().sum()\n",
    "print(missing_summary[missing_summary > 0])\n",
    "\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785467e",
   "metadata": {},
   "source": [
    "## 3. ðŸ“Š Numeric Columns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767837d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numeric columns: ['amount', 'balance_after']\n",
    "numeric_cols = ['amount', 'balance_after']\n",
    "\n",
    "if len(numeric_cols) > 0:\n",
    "    print(\"=== NUMERIC STATISTICS ===\")\n",
    "    display(df[numeric_cols].describe())\n",
    "    \n",
    "    # Create distribution plots\n",
    "    n_cols = min(len(numeric_cols), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(n_cols):\n",
    "        col = numeric_cols[i]\n",
    "        df[col].hist(bins=30, ax=axes[i], alpha=0.7)\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece59b30",
   "metadata": {},
   "source": [
    "## 4. ðŸ“‹ Categorical Columns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical columns: ['transaction_id', 'account_id', 'customer_name', 'account_type', 'transaction_type', 'category', 'transaction_date', 'description', 'merchant', 'location', 'channel']\n",
    "categorical_cols = ['transaction_id', 'account_id', 'customer_name', 'account_type', 'transaction_type', 'category', 'transaction_date', 'description', 'merchant', 'location', 'channel']\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    print(\"=== CATEGORICAL ANALYSIS ===\")\n",
    "    \n",
    "    for col in categorical_cols[:3]:  # Show first 3 columns\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df[col].value_counts().head())\n",
    "        \n",
    "        # Create bar plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        df[col].value_counts().head(10).plot(kind='bar')\n",
    "        plt.title(f'Top Values in {col}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2833bb",
   "metadata": {},
   "source": [
    "## 5. ðŸ”— Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249fde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numeric columns\n",
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "if len(numeric_df.columns) > 1:\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find high correlations\n",
    "    high_corr = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            corr_val = corr_matrix.iloc[i, j]\n",
    "            if abs(corr_val) > 0.7:\n",
    "                high_corr.append(f\"{corr_matrix.columns[i]} <-> {corr_matrix.columns[j]}: {corr_val:.3f}\")\n",
    "    \n",
    "    if high_corr:\n",
    "        print(\"High correlations (|r| > 0.7):\")\n",
    "        for item in high_corr:\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0317b",
   "metadata": {},
   "source": [
    "## 6. âœ… Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb814ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality assessment\n",
    "quality_score = 98.4\n",
    "\n",
    "print(\"=== FINAL SUMMARY ===\")\n",
    "print(f\"Overall Quality Score: {quality_score}%\")\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Missing Values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDED NEXT STEPS ===\")\n",
    "print(\"1. Handle missing values (if any)\")\n",
    "print(\"2. Check for outliers in numeric columns\")\n",
    "print(\"3. Consider feature engineering\")\n",
    "print(\"4. Select target variable for machine learning\")\n",
    "print(\"5. Prepare data for modeling\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
