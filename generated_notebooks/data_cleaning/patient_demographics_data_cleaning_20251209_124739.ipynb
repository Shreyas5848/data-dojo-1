{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63a7fb6",
   "metadata": {},
   "source": [
    "# üßπ Data Cleaning Workflow: patient_demographics\n",
    "\n",
    "**Generated:** 2025-12-09 12:47:39  \n",
    "**Purpose:** Systematic data cleaning and preparation\n",
    "\n",
    "This notebook provides a comprehensive data cleaning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a92193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('D:\\data-dojo-1\\datasets\\healthcare\\patient_demographics.csv')\n",
    "df_original = df.copy()  # Keep backup\n",
    "\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(\"Starting data cleaning workflow...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4a346",
   "metadata": {},
   "source": [
    "## 1. üï≥Ô∏è Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623766d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_summary = df.isnull().sum()\n",
    "missing_percentage = (missing_summary / len(df)) * 100\n",
    "\n",
    "print(\"=== MISSING VALUES SUMMARY ===\")\n",
    "for col in missing_summary[missing_summary > 0].index:\n",
    "    count = missing_summary[col]\n",
    "    percentage = missing_percentage[col]\n",
    "    print(f\"{col}: {count} missing ({percentage:.1f}%)\")\n",
    "\n",
    "# Handle missing values\n",
    "# Option 1: Drop columns with >50% missing\n",
    "high_missing_cols = missing_percentage[missing_percentage > 50].index\n",
    "if len(high_missing_cols) > 0:\n",
    "    print(f\"\\nDropping columns with >50% missing: {list(high_missing_cols)}\")\n",
    "    df = df.drop(columns=high_missing_cols)\n",
    "\n",
    "# Option 2: Fill numeric columns with median\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().any():\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Option 3: Fill categorical columns with mode\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().any():\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "print(f\"\\nAfter cleaning - Missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2e1647",
   "metadata": {},
   "source": [
    "## 2. üóëÔ∏è Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309142ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle duplicates\n",
    "duplicates_before = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(f\"Duplicates removed: {duplicates_before}\")\n",
    "print(f\"New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd6393",
   "metadata": {},
   "source": [
    "## 3. ‚úÖ Cleaning Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96892120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=== CLEANING SUMMARY ===\")\n",
    "print(f\"Original shape: {df_original.shape}\")\n",
    "print(f\"Final shape: {df.shape}\")\n",
    "print(f\"Rows removed: {len(df_original) - len(df)}\")\n",
    "print(f\"Missing values remaining: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv('cleaned_dataset.csv', index=False)\n",
    "print(\"\\nCleaned dataset saved as 'cleaned_dataset.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
