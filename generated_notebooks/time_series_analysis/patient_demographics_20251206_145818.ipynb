{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41faa482",
   "metadata": {},
   "source": [
    "# üìÖ Time Series Analysis: patient_demographics\n",
    "\n",
    "**Generated:** 2025-12-06 14:58:18  \n",
    "**Type:** Time Series Modeling  \n",
    "**Dataset:** patient_demographics\n",
    "\n",
    "## üéØ Objective\n",
    "This notebook provides a comprehensive time series analysis workflow including decomposition, stationarity testing, forecasting, and model evaluation.\n",
    "\n",
    "## üìã Workflow Steps\n",
    "1. **Data Loading & Date Parsing**\n",
    "2. **Time Series Visualization**\n",
    "3. **Trend & Seasonality Decomposition**\n",
    "4. **Stationarity Testing**\n",
    "5. **Feature Engineering**\n",
    "6. **Forecasting Models**\n",
    "7. **Model Evaluation**\n",
    "8. **Future Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Time series specific imports\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"\\nüìö Available Time Series Methods:\")\n",
    "print(\"‚Ä¢ Seasonal Decomposition\")\n",
    "print(\"‚Ä¢ Stationarity Tests (ADF, KPSS)\")\n",
    "print(\"‚Ä¢ Exponential Smoothing\")\n",
    "print(\"‚Ä¢ Moving Averages\")\n",
    "print(\"‚Ä¢ Prophet (if installed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc82bed",
   "metadata": {},
   "source": [
    "## 1. üìÅ Data Loading & Date Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06178d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset - REPLACE 'your_file.csv' with your actual file path\n",
    "df = pd.read_csv('your_file.csv')\n",
    "\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn names: {list(df.columns)}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "\n",
    "display(df.head(10))\n",
    "\n",
    "# IMPORTANT: Define your date and value columns\n",
    "# REPLACE these with your actual column names\n",
    "date_column = 'date'      # ‚ö†Ô∏è UPDATE: Column containing dates/timestamps\n",
    "value_column = 'value'    # ‚ö†Ô∏è UPDATE: Column containing values to forecast\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Please update the following variables:\")\n",
    "print(f\"   date_column = '{date_column}'\")\n",
    "print(f\"   value_column = '{value_column}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse dates and set as index\n",
    "if date_column in df.columns and value_column in df.columns:\n",
    "    \n",
    "    # Convert to datetime\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "    \n",
    "    # Sort by date\n",
    "    df = df.sort_values(date_column)\n",
    "    \n",
    "    # Set date as index\n",
    "    df_ts = df.set_index(date_column)[[value_column]].copy()\n",
    "    \n",
    "    print(\"‚úÖ Date parsing successful!\")\n",
    "    print(f\"\\n=== TIME SERIES INFO ===\")\n",
    "    print(f\"Start Date: {df_ts.index.min()}\")\n",
    "    print(f\"End Date: {df_ts.index.max()}\")\n",
    "    print(f\"Duration: {df_ts.index.max() - df_ts.index.min()}\")\n",
    "    print(f\"Total observations: {len(df_ts)}\")\n",
    "    \n",
    "    # Detect frequency\n",
    "    if len(df_ts) > 1:\n",
    "        time_diffs = pd.Series(df_ts.index).diff().dropna()\n",
    "        most_common_diff = time_diffs.mode()[0]\n",
    "        print(f\"Detected frequency: {most_common_diff}\")\n",
    "    \n",
    "    # Check for missing dates\n",
    "    date_range = pd.date_range(start=df_ts.index.min(), end=df_ts.index.max(), freq='D')\n",
    "    missing_dates = date_range.difference(df_ts.index)\n",
    "    if len(missing_dates) > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  Missing dates detected: {len(missing_dates)}\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ No missing dates in the series\")\n",
    "    \n",
    "    display(df_ts.head())\n",
    "    display(df_ts.describe())\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Columns not found!\")\n",
    "    print(f\"Available columns: {list(df.columns)}\")\n",
    "    print(\"\\nPlease update date_column and value_column variables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659ec90",
   "metadata": {},
   "source": [
    "## 2. üìä Time Series Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd438d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the time series\n",
    "if 'df_ts' in locals():\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Original time series\n",
    "    axes[0, 0].plot(df_ts.index, df_ts[value_column], linewidth=0.8)\n",
    "    axes[0, 0].set_title(f'Time Series: {value_column}')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel(value_column)\n",
    "    \n",
    "    # Distribution\n",
    "    axes[0, 1].hist(df_ts[value_column], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].axvline(df_ts[value_column].mean(), color='red', linestyle='--', \n",
    "                       label=f'Mean: {df_ts[value_column].mean():.2f}')\n",
    "    axes[0, 1].set_title(f'Distribution of {value_column}')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Rolling statistics\n",
    "    window = min(30, len(df_ts) // 10)  # Adaptive window size\n",
    "    rolling_mean = df_ts[value_column].rolling(window=window).mean()\n",
    "    rolling_std = df_ts[value_column].rolling(window=window).std()\n",
    "    \n",
    "    axes[1, 0].plot(df_ts.index, df_ts[value_column], label='Original', alpha=0.5)\n",
    "    axes[1, 0].plot(df_ts.index, rolling_mean, label=f'{window}-period Moving Avg', color='red')\n",
    "    axes[1, 0].set_title('Time Series with Rolling Mean')\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    axes[1, 1].plot(df_ts.index, rolling_std, color='orange')\n",
    "    axes[1, 1].set_title(f'{window}-period Rolling Standard Deviation')\n",
    "    \n",
    "    # Box plot by period (if enough data)\n",
    "    if len(df_ts) > 365:\n",
    "        df_ts['year'] = df_ts.index.year\n",
    "        df_ts.boxplot(column=value_column, by='year', ax=axes[2, 0])\n",
    "        axes[2, 0].set_title('Distribution by Year')\n",
    "        df_ts.drop('year', axis=1, inplace=True)\n",
    "    else:\n",
    "        df_ts['month'] = df_ts.index.month\n",
    "        df_ts.boxplot(column=value_column, by='month', ax=axes[2, 0])\n",
    "        axes[2, 0].set_title('Distribution by Month')\n",
    "        df_ts.drop('month', axis=1, inplace=True)\n",
    "    \n",
    "    # Lag plot\n",
    "    pd.plotting.lag_plot(df_ts[value_column], lag=1, ax=axes[2, 1])\n",
    "    axes[2, 1].set_title('Lag Plot (lag=1)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä TIME SERIES STATISTICS:\")\n",
    "    print(f\"Mean: {df_ts[value_column].mean():.4f}\")\n",
    "    print(f\"Median: {df_ts[value_column].median():.4f}\")\n",
    "    print(f\"Std Dev: {df_ts[value_column].std():.4f}\")\n",
    "    print(f\"Min: {df_ts[value_column].min():.4f}\")\n",
    "    print(f\"Max: {df_ts[value_column].max():.4f}\")\n",
    "    print(f\"Skewness: {df_ts[value_column].skew():.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please complete data loading first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b260903e",
   "metadata": {},
   "source": [
    "## 3. üìà Trend & Seasonality Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose time series into components\n",
    "if 'df_ts' in locals():\n",
    "    \n",
    "    # Determine period for decomposition\n",
    "    # Adjust based on your data frequency\n",
    "    period = 12  # Monthly seasonality (change to 7 for weekly, 365 for yearly, etc.)\n",
    "    \n",
    "    print(f\"=== SEASONAL DECOMPOSITION (period={period}) ===\")\n",
    "    print(\"Adjust 'period' variable based on your data:\")\n",
    "    print(\"‚Ä¢ Daily data with weekly pattern: period=7\")\n",
    "    print(\"‚Ä¢ Monthly data with yearly pattern: period=12\")\n",
    "    print(\"‚Ä¢ Hourly data with daily pattern: period=24\")\n",
    "    \n",
    "    if len(df_ts) >= 2 * period:\n",
    "        try:\n",
    "            # Perform decomposition\n",
    "            decomposition = seasonal_decompose(df_ts[value_column], model='additive', period=period)\n",
    "            \n",
    "            # Plot components\n",
    "            fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "            \n",
    "            decomposition.observed.plot(ax=axes[0], title='Original Series')\n",
    "            decomposition.trend.plot(ax=axes[1], title='Trend Component')\n",
    "            decomposition.seasonal.plot(ax=axes[2], title='Seasonal Component')\n",
    "            decomposition.resid.plot(ax=axes[3], title='Residual Component')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Analyze components\n",
    "            trend = decomposition.trend.dropna()\n",
    "            seasonal = decomposition.seasonal.dropna()\n",
    "            residual = decomposition.resid.dropna()\n",
    "            \n",
    "            print(\"\\nüìä COMPONENT ANALYSIS:\")\n",
    "            print(f\"Trend range: {trend.min():.4f} to {trend.max():.4f}\")\n",
    "            print(f\"Seasonal amplitude: {seasonal.max() - seasonal.min():.4f}\")\n",
    "            print(f\"Residual std: {residual.std():.4f}\")\n",
    "            \n",
    "            # Seasonal strength\n",
    "            var_resid = residual.var()\n",
    "            var_seasonal = seasonal.var()\n",
    "            seasonal_strength = 1 - (var_resid / (var_resid + var_seasonal))\n",
    "            print(f\"\\nSeasonal strength: {seasonal_strength:.4f}\")\n",
    "            \n",
    "            if seasonal_strength > 0.7:\n",
    "                print(\"‚úÖ Strong seasonality detected\")\n",
    "            elif seasonal_strength > 0.3:\n",
    "                print(\"üìä Moderate seasonality detected\")\n",
    "            else:\n",
    "                print(\"üìâ Weak or no seasonality\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Decomposition failed: {str(e)}\")\n",
    "            print(\"Try adjusting the 'period' parameter\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Need at least {2*period} observations for decomposition\")\n",
    "        print(f\"Current observations: {len(df_ts)}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Please complete data loading first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fbdd71",
   "metadata": {},
   "source": [
    "## 4. üîç Stationarity Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa479e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for stationarity\n",
    "if 'df_ts' in locals():\n",
    "    \n",
    "    print(\"=== STATIONARITY TESTS ===\")\n",
    "    print(\"A stationary series has constant mean and variance over time.\")\n",
    "    print(\"Most forecasting models require stationary data.\\n\")\n",
    "    \n",
    "    series = df_ts[value_column].dropna()\n",
    "    \n",
    "    # Augmented Dickey-Fuller Test\n",
    "    print(\"üìä AUGMENTED DICKEY-FULLER (ADF) TEST:\")\n",
    "    adf_result = adfuller(series, autolag='AIC')\n",
    "    \n",
    "    print(f\"   Test Statistic: {adf_result[0]:.4f}\")\n",
    "    print(f\"   p-value: {adf_result[1]:.4f}\")\n",
    "    print(f\"   Critical Values:\")\n",
    "    for key, value in adf_result[4].items():\n",
    "        print(f\"      {key}: {value:.4f}\")\n",
    "    \n",
    "    if adf_result[1] < 0.05:\n",
    "        print(\"   ‚úÖ Result: Series is STATIONARY (reject null hypothesis)\")\n",
    "        adf_stationary = True\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  Result: Series is NON-STATIONARY (fail to reject null)\")\n",
    "        adf_stationary = False\n",
    "    \n",
    "    # KPSS Test\n",
    "    print(\"\\nüìä KPSS TEST:\")\n",
    "    try:\n",
    "        kpss_result = kpss(series, regression='c', nlags='auto')\n",
    "        \n",
    "        print(f\"   Test Statistic: {kpss_result[0]:.4f}\")\n",
    "        print(f\"   p-value: {kpss_result[1]:.4f}\")\n",
    "        print(f\"   Critical Values:\")\n",
    "        for key, value in kpss_result[3].items():\n",
    "            print(f\"      {key}: {value:.4f}\")\n",
    "        \n",
    "        if kpss_result[1] >= 0.05:\n",
    "            print(\"   ‚úÖ Result: Series is STATIONARY (fail to reject null)\")\n",
    "            kpss_stationary = True\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  Result: Series is NON-STATIONARY (reject null)\")\n",
    "            kpss_stationary = False\n",
    "    except:\n",
    "        kpss_stationary = None\n",
    "        print(\"   ‚ö†Ô∏è  KPSS test failed\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n=== STATIONARITY SUMMARY ===\")\n",
    "    if adf_stationary:\n",
    "        print(\"‚úÖ Series appears to be stationary\")\n",
    "        print(\"Ready for modeling without differencing\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Series is non-stationary\")\n",
    "        print(\"Recommendation: Apply differencing or detrending\")\n",
    "        \n",
    "        # Show differenced series\n",
    "        print(\"\\nüìä FIRST DIFFERENCE:\")\n",
    "        diff_series = series.diff().dropna()\n",
    "        adf_diff = adfuller(diff_series, autolag='AIC')\n",
    "        print(f\"   ADF p-value after differencing: {adf_diff[1]:.4f}\")\n",
    "        \n",
    "        if adf_diff[1] < 0.05:\n",
    "            print(\"   ‚úÖ First difference is stationary\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  May need second differencing\")\n",
    "            \n",
    "else:\n",
    "    print(\"‚ùå Please complete data loading first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e13ab9",
   "metadata": {},
   "source": [
    "## 5. üìä Autocorrelation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6423e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze autocorrelation\n",
    "if 'df_ts' in locals():\n",
    "    \n",
    "    series = df_ts[value_column].dropna()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # ACF of original series\n",
    "    plot_acf(series, lags=40, ax=axes[0, 0], title='ACF - Original Series')\n",
    "    \n",
    "    # PACF of original series\n",
    "    plot_pacf(series, lags=40, ax=axes[0, 1], title='PACF - Original Series')\n",
    "    \n",
    "    # ACF of differenced series\n",
    "    diff_series = series.diff().dropna()\n",
    "    plot_acf(diff_series, lags=40, ax=axes[1, 0], title='ACF - First Difference')\n",
    "    \n",
    "    # PACF of differenced series\n",
    "    plot_pacf(diff_series, lags=40, ax=axes[1, 1], title='PACF - First Difference')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä ACF/PACF INTERPRETATION GUIDE:\")\n",
    "    print(\"‚Ä¢ ACF shows correlation at different lags\")\n",
    "    print(\"‚Ä¢ PACF shows direct correlation (removing intermediate effects)\")\n",
    "    print(\"‚Ä¢ Significant spikes suggest important lags for modeling\")\n",
    "    print(\"‚Ä¢ Gradual decay in ACF suggests AR process\")\n",
    "    print(\"‚Ä¢ Sharp cutoff in ACF suggests MA process\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please complete data loading first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dbf590",
   "metadata": {},
   "source": [
    "## 6. üöÇ Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "if 'df_ts' in locals():\n",
    "    \n",
    "    # Use last 20% for testing\n",
    "    test_size = 0.2\n",
    "    split_idx = int(len(df_ts) * (1 - test_size))\n",
    "    \n",
    "    train = df_ts.iloc[:split_idx].copy()\n",
    "    test = df_ts.iloc[split_idx:].copy()\n",
    "    \n",
    "    print(\"=== TRAIN-TEST SPLIT ===\")\n",
    "    print(f\"Training period: {train.index.min()} to {train.index.max()}\")\n",
    "    print(f\"Testing period: {test.index.min()} to {test.index.max()}\")\n",
    "    print(f\"Training samples: {len(train)}\")\n",
    "    print(f\"Testing samples: {len(test)}\")\n",
    "    \n",
    "    # Visualize split\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(train.index, train[value_column], label='Training', color='blue')\n",
    "    plt.plot(test.index, test[value_column], label='Testing', color='orange')\n",
    "    plt.axvline(x=train.index.max(), color='red', linestyle='--', label='Train/Test Split')\n",
    "    plt.title('Train-Test Split')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(value_column)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please complete data loading first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c605fb84",
   "metadata": {},
   "source": [
    "## 7. ü§ñ Forecasting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b648a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple forecasting models\n",
    "if 'train' in locals() and 'test' in locals():\n",
    "    \n",
    "    forecast_results = {}\n",
    "    \n",
    "    print(\"=== TRAINING FORECASTING MODELS ===\\n\")\n",
    "    \n",
    "    # 1. Simple Moving Average\n",
    "    print(\"üìä 1. Simple Moving Average...\")\n",
    "    window = min(12, len(train) // 4)\n",
    "    sma_forecast = train[value_column].rolling(window=window).mean().iloc[-1]\n",
    "    sma_predictions = pd.Series([sma_forecast] * len(test), index=test.index)\n",
    "    \n",
    "    sma_rmse = np.sqrt(mean_squared_error(test[value_column], sma_predictions))\n",
    "    sma_mae = mean_absolute_error(test[value_column], sma_predictions)\n",
    "    \n",
    "    forecast_results['Simple Moving Average'] = {\n",
    "        'predictions': sma_predictions,\n",
    "        'rmse': sma_rmse,\n",
    "        'mae': sma_mae\n",
    "    }\n",
    "    print(f\"   RMSE: {sma_rmse:.4f}, MAE: {sma_mae:.4f}\")\n",
    "    \n",
    "    # 2. Exponential Smoothing (Simple)\n",
    "    print(\"\\nüìä 2. Simple Exponential Smoothing...\")\n",
    "    try:\n",
    "        ses_model = ExponentialSmoothing(train[value_column], trend=None, seasonal=None)\n",
    "        ses_fit = ses_model.fit()\n",
    "        ses_predictions = ses_fit.forecast(len(test))\n",
    "        ses_predictions.index = test.index\n",
    "        \n",
    "        ses_rmse = np.sqrt(mean_squared_error(test[value_column], ses_predictions))\n",
    "        ses_mae = mean_absolute_error(test[value_column], ses_predictions)\n",
    "        \n",
    "        forecast_results['Simple Exp Smoothing'] = {\n",
    "            'predictions': ses_predictions,\n",
    "            'rmse': ses_rmse,\n",
    "            'mae': ses_mae\n",
    "        }\n",
    "        print(f\"   RMSE: {ses_rmse:.4f}, MAE: {ses_mae:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Failed: {str(e)}\")\n",
    "    \n",
    "    # 3. Holt's Linear Trend\n",
    "    print(\"\\nüìä 3. Holt's Linear Trend...\")\n",
    "    try:\n",
    "        holt_model = ExponentialSmoothing(train[value_column], trend='add', seasonal=None)\n",
    "        holt_fit = holt_model.fit()\n",
    "        holt_predictions = holt_fit.forecast(len(test))\n",
    "        holt_predictions.index = test.index\n",
    "        \n",
    "        holt_rmse = np.sqrt(mean_squared_error(test[value_column], holt_predictions))\n",
    "        holt_mae = mean_absolute_error(test[value_column], holt_predictions)\n",
    "        \n",
    "        forecast_results[\"Holt's Linear\"] = {\n",
    "            'predictions': holt_predictions,\n",
    "            'rmse': holt_rmse,\n",
    "            'mae': holt_mae\n",
    "        }\n",
    "        print(f\"   RMSE: {holt_rmse:.4f}, MAE: {holt_mae:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è  Failed: {str(e)}\")\n",
    "    \n",
    "    # 4. Holt-Winters (if enough data for seasonality)\n",
    "    print(\"\\nüìä 4. Holt-Winters Exponential Smoothing...\")\n",
    "    seasonal_period = 12  # Adjust based on your data\n",
    "    \n",
    "    if len(train) >= 2 * seasonal_period:\n",
    "        try:\n",
    "            hw_model = ExponentialSmoothing(\n",
    "                train[value_column], \n",
    "                trend='add', \n",
    "                seasonal='add', \n",
    "                seasonal_periods=seasonal_period\n",
    "            )\n",
    "            hw_fit = hw_model.fit()\n",
    "            hw_predictions = hw_fit.forecast(len(test))\n",
    "            hw_predictions.index = test.index\n",
    "            \n",
    "            hw_rmse = np.sqrt(mean_squared_error(test[value_column], hw_predictions))\n",
    "            hw_mae = mean_absolute_error(test[value_column], hw_predictions)\n",
    "            \n",
    "            forecast_results['Holt-Winters'] = {\n",
    "                'predictions': hw_predictions,\n",
    "                'rmse': hw_rmse,\n",
    "                'mae': hw_mae\n",
    "            }\n",
    "            print(f\"   RMSE: {hw_rmse:.4f}, MAE: {hw_mae:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Failed: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  Not enough data for seasonal model (need {2*seasonal_period} points)\")\n",
    "    \n",
    "    # 5. Naive Forecast (baseline)\n",
    "    print(\"\\nüìä 5. Naive Forecast (baseline)...\")\n",
    "    naive_predictions = pd.Series([train[value_column].iloc[-1]] * len(test), index=test.index)\n",
    "    \n",
    "    naive_rmse = np.sqrt(mean_squared_error(test[value_column], naive_predictions))\n",
    "    naive_mae = mean_absolute_error(test[value_column], naive_predictions)\n",
    "    \n",
    "    forecast_results['Naive (Baseline)'] = {\n",
    "        'predictions': naive_predictions,\n",
    "        'rmse': naive_rmse,\n",
    "        'mae': naive_mae\n",
    "    }\n",
    "    print(f\"   RMSE: {naive_rmse:.4f}, MAE: {naive_mae:.4f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Model training completed!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Please complete train-test split first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70745d",
   "metadata": {},
   "source": [
    "## 8. üìà Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3692e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "if 'forecast_results' in locals() and len(forecast_results) > 0:\n",
    "    \n",
    "    print(\"=== MODEL COMPARISON ===\\n\")\n",
    "    \n",
    "    # Create comparison dataframe\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Model': list(forecast_results.keys()),\n",
    "        'RMSE': [results['rmse'] for results in forecast_results.values()],\n",
    "        'MAE': [results['mae'] for results in forecast_results.values()]\n",
    "    })\n",
    "    \n",
    "    comparison_df = comparison_df.sort_values('RMSE')\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Best model\n",
    "    best_model_name = comparison_df.iloc[0]['Model']\n",
    "    best_predictions = forecast_results[best_model_name]['predictions']\n",
    "    \n",
    "    print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "    print(f\"   RMSE: {forecast_results[best_model_name]['rmse']:.4f}\")\n",
    "    print(f\"   MAE: {forecast_results[best_model_name]['mae']:.4f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Plot 1: All forecasts comparison\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(train.index, train[value_column], label='Training', color='blue', alpha=0.7)\n",
    "    plt.plot(test.index, test[value_column], label='Actual', color='black', linewidth=2)\n",
    "    \n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(forecast_results)))\n",
    "    for (name, results), color in zip(forecast_results.items(), colors):\n",
    "        plt.plot(test.index, results['predictions'], label=f'{name}', linestyle='--', color=color)\n",
    "    \n",
    "    plt.axvline(x=train.index.max(), color='red', linestyle=':', alpha=0.5)\n",
    "    plt.title('Forecast Comparison')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(value_column)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    # Plot 2: Best model detailed view\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(test.index, test[value_column], label='Actual', color='black', linewidth=2)\n",
    "    plt.plot(test.index, best_predictions, label=f'{best_model_name} Forecast', \n",
    "             color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    # Error bands\n",
    "    residuals = test[value_column] - best_predictions\n",
    "    std_resid = residuals.std()\n",
    "    plt.fill_between(test.index, \n",
    "                     best_predictions - 1.96*std_resid, \n",
    "                     best_predictions + 1.96*std_resid,\n",
    "                     alpha=0.2, color='red', label='95% Confidence Interval')\n",
    "    \n",
    "    plt.title(f'Best Model: {best_model_name}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(value_column)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Residual analysis\n",
    "    print(\"\\nüìä RESIDUAL ANALYSIS:\")\n",
    "    print(f\"Mean Residual: {residuals.mean():.4f} (should be ~0)\")\n",
    "    print(f\"Std Residual: {residuals.std():.4f}\")\n",
    "    \n",
    "    # Calculate MAPE\n",
    "    mape = np.mean(np.abs(residuals / test[value_column])) * 100\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    if mape < 10:\n",
    "        print(\"\\n‚úÖ Excellent forecast accuracy (MAPE < 10%)\")\n",
    "    elif mape < 20:\n",
    "        print(\"\\nüìä Good forecast accuracy (MAPE < 20%)\")\n",
    "    elif mape < 30:\n",
    "        print(\"\\n‚ö†Ô∏è  Moderate forecast accuracy (MAPE < 30%)\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Poor forecast accuracy (MAPE >= 30%)\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Please complete model training first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c85dcc",
   "metadata": {},
   "source": [
    "## 9. üîÆ Future Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate future predictions\n",
    "if 'best_model_name' in locals() and 'df_ts' in locals():\n",
    "    \n",
    "    # Number of periods to forecast\n",
    "    forecast_periods = 30  # ‚ö†Ô∏è Adjust based on your needs\n",
    "    \n",
    "    print(f\"=== GENERATING {forecast_periods}-PERIOD FORECAST ===\\n\")\n",
    "    \n",
    "    # Retrain best model on full data\n",
    "    full_series = df_ts[value_column]\n",
    "    \n",
    "    try:\n",
    "        if best_model_name == 'Holt-Winters':\n",
    "            final_model = ExponentialSmoothing(\n",
    "                full_series, \n",
    "                trend='add', \n",
    "                seasonal='add', \n",
    "                seasonal_periods=12\n",
    "            )\n",
    "        elif best_model_name == \"Holt's Linear\":\n",
    "            final_model = ExponentialSmoothing(full_series, trend='add', seasonal=None)\n",
    "        else:\n",
    "            final_model = ExponentialSmoothing(full_series, trend=None, seasonal=None)\n",
    "        \n",
    "        final_fit = final_model.fit()\n",
    "        future_forecast = final_fit.forecast(forecast_periods)\n",
    "        \n",
    "        # Create future dates\n",
    "        last_date = df_ts.index.max()\n",
    "        future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=forecast_periods)\n",
    "        future_forecast.index = future_dates\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        # Historical data (last 100 points)\n",
    "        recent_data = df_ts.tail(min(100, len(df_ts)))\n",
    "        plt.plot(recent_data.index, recent_data[value_column], label='Historical', color='blue')\n",
    "        \n",
    "        # Forecast\n",
    "        plt.plot(future_forecast.index, future_forecast.values, label='Forecast', \n",
    "                color='red', linestyle='--', linewidth=2)\n",
    "        \n",
    "        # Confidence intervals\n",
    "        std = full_series.std()\n",
    "        plt.fill_between(future_forecast.index,\n",
    "                        future_forecast.values - 1.96*std,\n",
    "                        future_forecast.values + 1.96*std,\n",
    "                        alpha=0.2, color='red', label='95% CI')\n",
    "        \n",
    "        plt.axvline(x=last_date, color='green', linestyle=':', label='Forecast Start')\n",
    "        plt.title(f'{forecast_periods}-Period Forecast using {best_model_name}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(value_column)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Display forecast values\n",
    "        print(\"üìä FORECAST VALUES:\")\n",
    "        forecast_df = pd.DataFrame({\n",
    "            'Date': future_forecast.index,\n",
    "            'Forecast': future_forecast.values\n",
    "        })\n",
    "        display(forecast_df.head(15))\n",
    "        \n",
    "        print(f\"\\nüìà Forecast Summary:\")\n",
    "        print(f\"   Start: {future_forecast.iloc[0]:.4f}\")\n",
    "        print(f\"   End: {future_forecast.iloc[-1]:.4f}\")\n",
    "        print(f\"   Mean: {future_forecast.mean():.4f}\")\n",
    "        print(f\"   Trend: {'üìà Increasing' if future_forecast.iloc[-1] > future_forecast.iloc[0] else 'üìâ Decreasing'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Forecast generation failed: {str(e)}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Please complete model evaluation first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55470e35",
   "metadata": {},
   "source": [
    "## 10. ‚úÖ Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=== üìÖ TIME SERIES ANALYSIS COMPLETE ===\")\n",
    "print()\n",
    "\n",
    "if 'best_model_name' in locals():\n",
    "    best_rmse = forecast_results[best_model_name]['rmse']\n",
    "    best_mae = forecast_results[best_model_name]['mae']\n",
    "    \n",
    "    print(\"üìä ANALYSIS SUMMARY:\")\n",
    "    print(f\"‚Ä¢ Dataset: {dataset_name}\")\n",
    "    print(f\"‚Ä¢ Time Period: {df_ts.index.min()} to {df_ts.index.max()}\")\n",
    "    print(f\"‚Ä¢ Observations: {len(df_ts)}\")\n",
    "    print(f\"‚Ä¢ Best Model: {best_model_name}\")\n",
    "    print(f\"‚Ä¢ RMSE: {best_rmse:.4f}\")\n",
    "    print(f\"‚Ä¢ MAE: {best_mae:.4f}\")\n",
    "    \n",
    "    print(\"\\nüöÄ RECOMMENDED NEXT STEPS:\")\n",
    "    print(\"1. üîß Try ARIMA/SARIMA models for potentially better results\")\n",
    "    print(\"2. üìä Experiment with different seasonal periods\")\n",
    "    print(\"3. üéØ Add external regressors (holidays, events, etc.)\")\n",
    "    print(\"4. üîÑ Set up regular model retraining pipeline\")\n",
    "    print(\"5. üìà Monitor forecast accuracy over time\")\n",
    "    \n",
    "    print(\"\\nüõ†Ô∏è  ADVANCED TECHNIQUES TO EXPLORE:\")\n",
    "    print(\"‚Ä¢ ARIMA/SARIMA models (statsmodels)\")\n",
    "    print(\"‚Ä¢ Prophet (Facebook's forecasting library)\")\n",
    "    print(\"‚Ä¢ LSTM neural networks (for complex patterns)\")\n",
    "    print(\"‚Ä¢ XGBoost with time-based features\")\n",
    "    print(\"‚Ä¢ Ensemble methods combining multiple models\")\n",
    "    \n",
    "    print(\"\\nüíæ SAVE YOUR MODEL:\")\n",
    "    print(\"# Uncomment to save\")\n",
    "    print(\"# import joblib\")\n",
    "    print(\"# joblib.dump(final_fit, 'timeseries_model.pkl')\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Analysis incomplete. Please run all previous cells.\")\n",
    "\n",
    "print(\"\\nüéâ Time series analysis workflow completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
